---
title: Modern Data Stack in a Box
date: 2019-08-01 00:00:00
description: Using the declarative code-first data integration engine Meltano, it is possible to bind multiple modern data tools together for a rapid cost effective and modern data stack.
featured_image: '/images/projects/meltano.jpg'
---

Data is everything. Having highly optimized data quality will give the organization a great advantage. 

Big organizations use expensive cloud servers, that has couple to the latest modern data stack also with a cloud solution. However, many of these data technologies are free and open-source even for enterprise, if it is running on a local server. Using the declarative code-first data integration engine Meltano, it is possible to bind everything together running this highly optimized data stack.

Doing so, will quickly put your data majority miles ahead, with a fraction of traditional-cloud cost.

*This ETL makes an extremely powerful setup, for small to medium-sized organizations or project-based data.*

### What are the key benefits?
* ✅ **Automation.**  Orchestration tool will automatically handle the data-pipeline.
* ✅ **Transparent.** Well documented and optimized syntax will make the data less error-prone and fast to debug.
* ✅ **Version control.** Easily roll-back versions, and keep check of the development
* ✅ **Scalable.** Allows for many data sources. Also, all technologies are easily switchable - for example switching duckdb for snowflake. 
* ✅ **Collaboration.** These tools a made for collaboration across data specialist. Furthermore, best tools and practice is used, so professionals will be able to continue the work rapidly. 
* ✅ **Configurable.** Thousands of data utilities exists to help (great-expectations, Apache Superset, etc.)
* ✅ **Standardization.** Use the standard best practice, no weird language or rules collaboration should know about.
* ✅ **Single source of truth.** Work towards a single place where data is handle and gain trust in the data again.
* ✅ **Development environment.** Sensitive data or development time till benefit from dev-stage-prod environments.

### We Propose

While the different components can either be swapped down the line or simply just added, we propose the following stack:

* [Meltano](https://meltano.com/) as the integration engine. Seamlessly integrate data sources, build pipelines, and track data quality with a powerful data integration platform.
* [DBT](https://www.getdbt.com/) as the data transformation and documentation tool. DBT enables you to transform and model your data in a consistent and reproducible manner, ensuring data integrity and consistency across your organization.
* [Dagster](https://dagster.io/) as the orchestration tool. Dagster provides a robust orchestration platform that automates and manages data pipelines, streamlining data processing and ensuring seamless integration with your existing systems.
* [DuckDB](https://duckdb.org/) for the database tech.  The Lightweight SQL Database for Efficient Data Processing.
* [Evidence](https://evidence.dev/) for the BI tool. Automate data collection, transformation, and ingestion with a unified data observability platform.



### Curious how your organization can get the data lead?

We can help you implement these technologies seamlessly, ensuring that your data stack aligns with your specific business needs. We offer a demo project showing the stack described above.

<a href="#" class="header__cta button--fill contact-trigger js-contact">Get In Touch</a>